{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Keras\n",
    "\n",
    "The goal here is to try Deep Learning to see if the accuracy of the image classification improves, as Deep Learning and CNNs \n",
    "tend to perform well for complex data such as image.\n",
    "\n",
    "The suggested architecture is the following :\n",
    "1. Input Layer (3 channel image input layer)\n",
    "* Convolutional (2D)\n",
    "* Max Pooling\n",
    "* Convolutional (2D)\n",
    "* Max Pooling\n",
    "* Dense (Output Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from PIL import Image\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten # Core layers used for neural networks\n",
    "from keras.layers import Convolution2D, MaxPooling2D # CNN layers used for image processing\n",
    "from keras.utils import np_utils # Tools to transform the data\n",
    "from keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(key):\n",
    "    label_mapping = {\n",
    "        \"axes\" : \"1\",\n",
    "        \"boots\" : \"2\",\n",
    "        \"carabiners\" : \"3\",\n",
    "        \"crampons\" : \"4\",\n",
    "        \"gloves\" : \"5\",\n",
    "        \"hardshell_jackets\" : \"6\",\n",
    "        \"harnesses\" : \"7\",\n",
    "        \"helmets\" : \"8\",\n",
    "        \"insulated_jackets\" : \"9\",\n",
    "        \"pulleys\" : \"10\",\n",
    "        \"rope\" : \"11\",\n",
    "        \"tents\" : \"12\",\n",
    "    }\n",
    "    return int(label_mapping[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: gear_images//axes/\n",
      "Folder: gear_images//boots/\n",
      "Folder: gear_images//carabiners/\n",
      "Folder: gear_images//crampons/\n",
      "Folder: gear_images//gloves/\n",
      "Folder: gear_images//hardshell_jackets/\n",
      "Folder: gear_images//harnesses/\n",
      "Folder: gear_images//helmets/\n",
      "Folder: gear_images//insulated_jackets/\n",
      "Folder: gear_images//pulleys/\n",
      "Folder: gear_images//rope/\n",
      "Folder: gear_images//tents/\n"
     ]
    }
   ],
   "source": [
    "rootDir = 'gear_images/'\n",
    "directories = ['axes', 'boots', 'carabiners', 'crampons', 'gloves', 'hardshell_jackets', 'harnesses',\n",
    "              'helmets', 'insulated_jackets', 'pulleys', 'rope', 'tents']\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "category = [] # List of labels (numbered [1,12])\n",
    "pixel_array = [] # List of Flatten Pixel array for each image\n",
    "\n",
    "for directory in directories:   \n",
    "    folderPath = rootDir + '/' + directory + '/'\n",
    "    print('Folder: {}'.format(folderPath))\n",
    "    for fname in os.listdir(folderPath):\n",
    "        if fname.endswith('resized_equalized.jpeg'):\n",
    "            im = Image.open(folderPath + fname)\n",
    "            im_array = np.array(im, dtype=float)\n",
    "            \n",
    "            # Append data to list\n",
    "            category.append(label_encoder(directory))\n",
    "            pixel_array.append(im_array)\n",
    "\n",
    "pd_dict = {\n",
    "    'pixel_array' : pixel_array,\n",
    "    'category' : category,\n",
    "}\n",
    "df = pd.DataFrame(pd_dict)\n",
    "df['category'] = pd.to_numeric(df['category'])\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2063, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2063 entries, 1304 to 860\n",
      "Data columns (total 2 columns):\n",
      "pixel_array    2063 non-null object\n",
      "category       2063 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 48.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_array</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>[[[255.0, 255.0, 255.0], [255.0, 255.0, 255.0]...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>[[[255.0, 255.0, 255.0], [255.0, 255.0, 255.0]...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>[[[255.0, 255.0, 255.0], [255.0, 255.0, 255.0]...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[[[28.0, 29.0, 33.0], [2.0, 3.0, 7.0], [35.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pixel_array  category\n",
       "1304  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...         7\n",
       "2028  [[[255.0, 255.0, 255.0], [255.0, 255.0, 255.0]...        12\n",
       "693   [[[255.0, 255.0, 255.0], [255.0, 255.0, 255.0]...         5\n",
       "1788  [[[255.0, 255.0, 255.0], [255.0, 255.0, 255.0]...        11\n",
       "29    [[[28.0, 29.0, 33.0], [2.0, 3.0, 7.0], [35.0, ...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spit into Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Training and Testing Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['pixel_array'].values.tolist(),\n",
    "                                                    df['category'].values.tolist(),\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['category'])\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 128, 128, 3)\n",
      "(413, 128, 128, 3)\n",
      "(1650,)\n",
      "(413,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess input data for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our dataset from having shape (width, height, depth) to (depth, width, height)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[3], X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[3], X_test.shape[1], X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 3, 128, 128)\n",
      "(413, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our data type to float32 and normalize our data values to the range [0, 1].\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 12)\n",
      "image 1: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "image 2: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "image 3: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "image 4: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "image 5: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "image 6: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "image 7: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "image 8: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "image 9: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "image 10: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Convert 1-dimensional class arrays to 12-dimensional class matrices\n",
    "# For each image, instead of having a scalar value in range(1,12), we now have an array of 0s and 1\n",
    "Y_train = np_utils.to_categorical(y_train, 13)[:,1:]\n",
    "Y_test = np_utils.to_categorical(y_test, 13)[:,1:]\n",
    "print(Y_train.shape)\n",
    "# Display the first 10 labels\n",
    "for i in range(0,10):\n",
    "    print('image ' + str(i+1) + ': ' + str(Y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape parameter should be the shape of 1 sample. Here we have (3, 128, 128) that corresponds to  the (depth, width, height) of each image.\n",
    "\n",
    "Parameters used: \n",
    "* 32 convolution filters\n",
    "* 1 row in each convolution kernel\n",
    "* 1 column in each convolution kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", input_shape=(3, 128, 1...)`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# First Input Layer\n",
    "model.add(Convolution2D(32, 1, 1, activation='relu', input_shape=(3,128,128)))\n",
    "\n",
    "# Adding more layers to our model\n",
    "model.add(Convolution2D(32, 1, 1, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Dropout(0.25)) #to prevent from overfitting\n",
    "\n",
    "# Additional layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3, 128, 128)\n",
      "(None, 12)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1280 - acc: 0.9564\n",
      "Epoch 2/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1405 - acc: 0.9473\n",
      "Epoch 3/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1290 - acc: 0.9545\n",
      "Epoch 4/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1146 - acc: 0.9570\n",
      "Epoch 5/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1128 - acc: 0.9600\n",
      "Epoch 6/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1106 - acc: 0.9624\n",
      "Epoch 7/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.0819 - acc: 0.9758\n",
      "Epoch 8/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1165 - acc: 0.9576\n",
      "Epoch 9/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1244 - acc: 0.9527\n",
      "Epoch 10/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1069 - acc: 0.9618\n",
      "Epoch 11/20\n",
      "1650/1650 [==============================] - 4s 2ms/step - loss: 0.1063 - acc: 0.9606\n",
      "Epoch 12/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.0773 - acc: 0.9727\n",
      "Epoch 13/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.0849 - acc: 0.9648\n",
      "Epoch 14/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.0976 - acc: 0.9630\n",
      "Epoch 15/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.1140 - acc: 0.9606\n",
      "Epoch 16/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.0883 - acc: 0.9721\n",
      "Epoch 17/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.0846 - acc: 0.9667\n",
      "Epoch 18/20\n",
      "1650/1650 [==============================] - 4s 2ms/step - loss: 0.0749 - acc: 0.9715\n",
      "Epoch 19/20\n",
      "1650/1650 [==============================] - 4s 2ms/step - loss: 0.0788 - acc: 0.9721\n",
      "Epoch 20/20\n",
      "1650/1650 [==============================] - 3s 2ms/step - loss: 0.0869 - acc: 0.9685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16d253ff518>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 0s 400us/step\n",
      "['loss', 'acc']\n",
      "0.5104563689405058 0.8837772386991949\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, Y_test)\n",
    "print(model.metrics_names)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gear_classifier.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
